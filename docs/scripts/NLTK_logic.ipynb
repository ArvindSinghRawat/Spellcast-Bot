{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArvindSinghRawat/Spellcast-Bot/blob/feature%2Fv1%2Farvind%2Fscraping-logic/docs/scripts/NLTK_logic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSmGijnI0sfB"
      },
      "source": [
        "# Logic to create huge corpus of words using NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yxxtn-jNJ3-"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9-CCLi50zJk"
      },
      "source": [
        "### Setting dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5eJkAR-0yIJ"
      },
      "outputs": [],
      "source": [
        "!pip3 install --user -U nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9eXj_qy07z4"
      },
      "source": [
        "### General imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9qWc7ft1GnH"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import nombank, propbank, stopwords, brown\n",
        "import nltk\n",
        "import re\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcT49xeMHIS"
      },
      "source": [
        "### Adding different corpus to populate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc4pdbVp1fwZ"
      },
      "outputs": [],
      "source": [
        "nltk.download(\"brown\")\n",
        "nltk.download(\"nombank.1.0\")\n",
        "nltk.download(\"propbank\")\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6DcG_LdLwoH"
      },
      "outputs": [],
      "source": [
        "# Ensuring all of them are downloaded\n",
        "brown.ensure_loaded()\n",
        "nombank.ensure_loaded()\n",
        "propbank.ensure_loaded()\n",
        "stopwords.ensure_loaded()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOTPz0iQNflB"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDW8E7FXMSgQ"
      },
      "source": [
        "### Preparing types of words expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p2HI4b_Edmn"
      },
      "outputs": [],
      "source": [
        "word_dict = dict()\n",
        "known_types = dict()\n",
        "DESCRIPTION = 'description'\n",
        "WORD_LIST = 'word_list'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c-lQDp3HvUs"
      },
      "outputs": [],
      "source": [
        "# Preparing types\n",
        "\n",
        "known_types['CC'] = {DESCRIPTION: 'coordinating conjunction (and, or)'}\n",
        "known_types['CD'] = {DESCRIPTION: 'cardinal numeral (one, two, 2, etc.)'}\n",
        "known_types['CS'] = {DESCRIPTION: 'subordinating conjunction (if, although)'}\n",
        "known_types['EX'] = {DESCRIPTION: 'existential there'}\n",
        "known_types['IN'] = {DESCRIPTION: 'preposition (in, at, on)'}\n",
        "known_types['JJ'] = {DESCRIPTION: 'adjective'}\n",
        "known_types['JJA'] = {DESCRIPTION: 'adjective + Auxiliary'}\n",
        "known_types['JJC'] = {DESCRIPTION: 'adjective, Comparative'}\n",
        "known_types['JJCC'] = {DESCRIPTION: 'Adjective + Conjunction'}\n",
        "known_types['JJS'] = {DESCRIPTION: 'semantically superlative adjective (chief, top)'}\n",
        "known_types['JJF'] = {DESCRIPTION: 'Adjective + Female'}\n",
        "known_types['JJM'] = {DESCRIPTION: 'Adjective + Male'}\n",
        "known_types['NN'] = {DESCRIPTION: 'singular or mass noun'}\n",
        "known_types['NNA'] = {DESCRIPTION: 'Noun + Auxiliary'}\n",
        "known_types['NNC'] = {DESCRIPTION: 'Noun + Conjunction'}\n",
        "known_types['NNS'] = {DESCRIPTION: 'plural noun'}\n",
        "known_types['NNP'] = {DESCRIPTION: 'proper noun or part of name phrase'}\n",
        "known_types['NNPC'] = {DESCRIPTION: 'proper noun + Conjunction'}\n",
        "known_types['PRP'] = {DESCRIPTION: 'personal pronoun, singular'}\n",
        "known_types['PRPS'] = {DESCRIPTION: 'personal pronoun, plural'}\n",
        "known_types['PRP$'] = {DESCRIPTION: 'Possessive pronoun'}\n",
        "known_types['RB'] = {DESCRIPTION: 'adverb'}\n",
        "known_types['RBR'] = {DESCRIPTION: 'comparative adverb'}\n",
        "known_types['RBS'] = {DESCRIPTION: 'superlative adverb'}\n",
        "known_types['STP'] = {DESCRIPTION: 'stopwords'}\n",
        "known_types['VB'] = {DESCRIPTION: 'verb, base form'}\n",
        "known_types['VBA'] = {DESCRIPTION: 'verb + Auxiliary, singular, present'}\n",
        "known_types['VBD'] = {DESCRIPTION: 'verb, past tense'}\n",
        "known_types['VBG'] = {DESCRIPTION: 'verb, present participle/gerund'}\n",
        "known_types['VBN'] = {DESCRIPTION: 'verb, past participle'}\n",
        "known_types['VBZ'] = {DESCRIPTION: 'verb, 3rd. singular present'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ml12unuMnkK"
      },
      "source": [
        "### Methods to pre-process text or filter out unwanted words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1bwvK21L0Gl"
      },
      "outputs": [],
      "source": [
        "def process_raw_text(line: str) -> str:\n",
        "  \"\"\"Reads the raw text and filters unwanted data out of it. Returns List with single word in each element\n",
        "  \"\"\"\n",
        "  # TODO: substitute `- ` with empty word\n",
        "  # TODO: Split words, add words greater than 1 char in list\n",
        "  # TODO: convert words to small caps\n",
        "  line = re.sub(\"-\\s+\", \"\", line)\n",
        "  word = line.strip()\n",
        "  all_same = all(ch == word[0] for ch in word)\n",
        "  if len(word) > 1 and word.isalpha() and not word.isupper() and not all_same:\n",
        "    return word.lower()\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xLK-1ZeM08F"
      },
      "source": [
        "### Preparing map of words tagged with proper category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0-yZnSES8e6"
      },
      "outputs": [],
      "source": [
        "def find_total_count(word_dict):\n",
        "  final_count = 0\n",
        "  for (key, value) in word_dict.items():\n",
        "    final_count += len(value)\n",
        "  return final_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMEqXF4b6lZZ",
        "outputId": "93d75b7a-1c48-4a16-fe13-92dcd9280c4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35972"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Brown corpus data processing\n",
        "\n",
        "for (word, tag) in brown.tagged_words():\n",
        "  if tag in known_types:\n",
        "    ls = word_dict.get(tag, None)\n",
        "    if ls is None:\n",
        "      ls = list()\n",
        "      word_dict[tag] = ls\n",
        "    word = process_raw_text(word)\n",
        "    if word is not None and word not in ls:\n",
        "      ls.append(word)\n",
        "\n",
        "find_total_count(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eT5iceL7OVZv"
      },
      "outputs": [],
      "source": [
        "# # Stop words data processing\n",
        "\n",
        "# stopword_list = word_dict.get('STP', None)\n",
        "# if stopword_list is None:\n",
        "#   stopword_list = list()\n",
        "#   word_dict['STP'] = stopword_list\n",
        "# for word in stopwords.words('english'):\n",
        "#   word = process_raw_text(word)\n",
        "#   if word is not None and word not in stopword_list:\n",
        "#     stopword_list.append(word)\n",
        "# stopword_list = None\n",
        "\n",
        "# find_total_count(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8vHTY2ZDGFX",
        "outputId": "1d7b9831-6807-4659-c297-e61d3489a8a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "36926"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Nombank data processing\n",
        "\n",
        "noun_list = word_dict.get('NN', None)\n",
        "if noun_list is None:\n",
        "  noun_list = list()\n",
        "  word_dict['NN'] = noun_list\n",
        "for word in nombank.nouns():\n",
        "  word = process_raw_text(word)\n",
        "  if word is not None and word not in noun_list:\n",
        "    noun_list.append(word)\n",
        "noun_list = None\n",
        "\n",
        "find_total_count(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H70ZKgvSYGx",
        "outputId": "55baf134-a82c-418e-c4e1-a9de66a08916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "38139"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Propbank data processing\n",
        "\n",
        "verb_list = word_dict.get('VB', None)\n",
        "if verb_list is None:\n",
        "  verb_list = list()\n",
        "  word_dict['VB'] = verb_list\n",
        "for word in propbank.verbs():\n",
        "  word = process_raw_text(word)\n",
        "  if word is not None and word not in verb_list:\n",
        "    verb_list.append(word)\n",
        "verb_list = None\n",
        "\n",
        "find_total_count(word_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0WjAZD5bk8U"
      },
      "source": [
        "## Util classes and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MkIOteqkbsOk"
      },
      "outputs": [],
      "source": [
        "# Defining constants\n",
        "class WordType(Enum):\n",
        "  VERB = 'v.'\n",
        "  NOUN = 'n.'\n",
        "  ABBREVIATION = 'abbr.'\n",
        "  ADJECTIVE = 'adj.'\n",
        "  ADVERB = 'adv.'\n",
        "  NUMBER = 'num.'\n",
        "  PRONOUN = 'p.'\n",
        "  CONJUNCTION = 'conj.'\n",
        "  PREPOSITION = 'pre.'\n",
        "  INTERJECTION = 'int.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9Fh3HGj-bp-n"
      },
      "outputs": [],
      "source": [
        "def map_type(input: str) -> WordType: \n",
        "  if input is None:\n",
        "    return None\n",
        "  input = input.strip()\n",
        "  if len(input) < 1:\n",
        "    return None\n",
        "  if input == 'v' or input.startswith('VB'):\n",
        "    return WordType.VERB\n",
        "  elif input == 'adj' or input.startswith('JJ') :\n",
        "    return WordType.ADJECTIVE\n",
        "  elif input == 'n' or input.startswith('NN'):\n",
        "    return WordType.NOUN\n",
        "  elif input == 'abbr':\n",
        "    return WordType.ABBREVIATION\n",
        "  elif input == 'adv' or input.startswith('RB'):\n",
        "    return WordType.ADVERB\n",
        "  elif input in ['CC', 'CS']:\n",
        "    return WordType.CONJUNCTION\n",
        "  elif input == 'CD':\n",
        "    return WordType.NUMBER\n",
        "  elif input == 'EX' or input.startswith('PR'):\n",
        "    return WordType.PRONOUN\n",
        "  elif input in ['IN', 'STP']:\n",
        "    return WordType.PREPOSITION\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nYEAOuWNvBN"
      },
      "source": [
        "## Actual processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIz_TvovUSoT"
      },
      "source": [
        "### Prepare standard Json\n",
        "Like\n",
        "```json\n",
        "{\n",
        "   \"<ACTUAL_WORD>\" : {\n",
        "     \"word\": \"<ACTUAL_WORD>\",\n",
        "     \"meaning\": [\n",
        "      {\n",
        "         \"value\" : \"<ACTUAL_MEANING>\",\n",
        "         \"type\" : \"NOUN|VERB|ADJ|ABBR\",\n",
        "         \"index\" : 0\n",
        "      },\n",
        "      {\n",
        "         ... // Different meaning or type\n",
        "      }\n",
        "      ...  // Other meanings or types\n",
        "   ]\n",
        "   },\n",
        "   ... // More Words\n",
        "}\n",
        "```\n",
        "\n",
        "Here, Json object against the outermost root key i.e. `<ACTUAL_WORD>` is nullable, which means there is no context for the word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ythRn2nfWzX9"
      },
      "source": [
        "#### Context and expectation\n",
        "Here, all of the words didn't had any meaning with them. So, the only thing that need to be saved is type and word. Finally, the output would be:\n",
        "```json\n",
        "{\n",
        "  \"<ACTUAL_WORD>\": {\n",
        "    \"meaning\": [\n",
        "      {\n",
        "        \"type\": \"NOUN|VERB|ADJ|ABBR\",\n",
        "        \"index\": 0\n",
        "      },\n",
        "      {\n",
        "        ...\n",
        "      }\n",
        "      ... // More types, maybe\n",
        "    ]\n",
        "  },\n",
        "  ... // More words\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "skjPsveOZUGT"
      },
      "outputs": [],
      "source": [
        "standard_dict = dict()\n",
        "for (tag , word_list) in word_dict.items():\n",
        "  word_type = map_type(tag)\n",
        "  for word in word_list:\n",
        "    details = standard_dict.get(word, None)\n",
        "    if details is None:\n",
        "      details = dict()\n",
        "      standard_dict[word] = details\n",
        "    ls = details.get('meaning', list())\n",
        "    do_skip = False\n",
        "    for meaning in ls:\n",
        "      if meaning.get('type', None) == word_type.name:\n",
        "        do_skip = True\n",
        "        break\n",
        "    if do_skip:\n",
        "      continue\n",
        "    ls.append({\n",
        "        'type': word_type.name,\n",
        "        'index': len(ls)\n",
        "    })\n",
        "    details['meaning'] = ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OGGcXCAGx9W-"
      },
      "outputs": [],
      "source": [
        "# Serializing json\n",
        "json_object = json.dumps(standard_dict, separators=(',', ':'))\n",
        " \n",
        "# Writing to sample.json\n",
        "with open(\"output/dictionary-nltk.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN4GnrKbieQ8hGofk6RHQp+",
      "collapsed_sections": [
        "6yxxtn-jNJ3-",
        "g9-CCLi50zJk",
        "wDW8E7FXMSgQ"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
